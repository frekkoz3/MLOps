{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!export FLASK_APP=Class6_model_api.py\n",
    "!flask run --host=0.0.0.0 --port=5001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (150, 4)\n",
      "Feature Names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target, name='target')\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape)\n",
    "print(\"Feature Names:\", iris.feature_names)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 105\n",
      "Test samples: 45\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))\n",
    "\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 3, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Best CV Accuracy: 0.9619047619047618\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 8, None],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9111111111111111\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.88        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Serialize (Save) the Model to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to best_random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "pickle_filename = \"best_random_forest_model.pkl\"\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "print(f\"✅ Model saved to {pickle_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Serve the Model via Flask API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Use Script (Class6_model_api.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Run Flask in Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "Exception in thread Thread-7 (run_flask):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\Utente\\Documents\\Università\\MLOps\\MLOps\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\"\u001b[0m, line \u001b[35m772\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_42888\\1069796380.py\"\u001b[0m, line \u001b[35m5\u001b[0m, in \u001b[35mrun_flask\u001b[0m\n",
      "    \u001b[31mapp.run\u001b[0m\u001b[1;31m(port=5001, debug=True)\u001b[0m\n",
      "    \u001b[31m~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\Utente\\Documents\\Università\\MLOps\\MLOps\\venv\\Lib\\site-packages\\flask\\app.py\"\u001b[0m, line \u001b[35m662\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mrun_simple\u001b[0m\u001b[1;31m(t.cast(str, host), port, self, **options)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\Utente\\Documents\\Università\\MLOps\\MLOps\\venv\\Lib\\site-packages\\werkzeug\\serving.py\"\u001b[0m, line \u001b[35m1115\u001b[0m, in \u001b[35mrun_simple\u001b[0m\n",
      "    \u001b[31mrun_with_reloader\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31msrv.serve_forever,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    ...<3 lines>...\n",
      "        \u001b[1;31mreloader_type=reloader_type,\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\Utente\\Documents\\Università\\MLOps\\MLOps\\venv\\Lib\\site-packages\\werkzeug\\_reloader.py\"\u001b[0m, line \u001b[35m452\u001b[0m, in \u001b[35mrun_with_reloader\u001b[0m\n",
      "    \u001b[31msignal.signal\u001b[0m\u001b[1;31m(signal.SIGTERM, lambda *args: sys.exit(0))\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\signal.py\"\u001b[0m, line \u001b[35m58\u001b[0m, in \u001b[35msignal\u001b[0m\n",
      "    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35msignal only works in main thread of the main interpreter\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "def run_flask():\n",
    "    app.run(port=5002, debug=True)\n",
    "\n",
    "thread = threading.Thread(target=run_flask)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Test the API Request (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response: {'prediction': 2}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)  # Wait for Flask to start\n",
    "\n",
    "sample = X_test.iloc[0].tolist()\n",
    "response = requests.post(\"http://127.0.0.1:5001/predict\", json={\"features\": sample})\n",
    "print(\"API Response:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -X POST http://127.0.0.1:5001/predict \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"features\": [5.1, 3.5, 1.4, 0.2]}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. AutoML Example (TPOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\Documents\\Università\\MLOps\\MLOps\\venv\\Lib\\site-packages\\stopit\\__init__.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TPOTClassifier.__init__() got an unexpected keyword argument 'generations'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     15\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     16\u001b[39m     X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# --- Initialize TPOT2 AutoML classifier ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m tpot = \u001b[43mTPOTClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# number of generations\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# number of pipelines per generation\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_time_mins\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# search duration\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# use all cores\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# --- Fit the TPOT model ---\u001b[39;00m\n\u001b[32m     29\u001b[39m tpot.fit(X_train, y_train)\n",
      "\u001b[31mTypeError\u001b[39m: TPOTClassifier.__init__() got an unexpected keyword argument 'generations'"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load the Iris dataset ---\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# --- Split data into training and test sets ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Initialize TPOT2 AutoML classifier ---\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,                # number of generations\n",
    "    population_size=20,           # number of pipelines per generation\n",
    "    random_state=42,\n",
    "    max_time_mins=2,              # search duration\n",
    "    n_jobs=1,                    # use all cores\n",
    ")\n",
    "\n",
    "# --- Fit the TPOT model ---\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on test data ---\n",
    "y_pred = tpot.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "# --- Visualize confusion matrix ---\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=iris.target_names).plot(cmap=\"Blues\")\n",
    "plt.title(\"TPOT2 Classifier - Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Access best pipeline ---\n",
    "best_model = tpot.fitted_pipeline_ \n",
    "print(\"\\nBest Pipeline:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
